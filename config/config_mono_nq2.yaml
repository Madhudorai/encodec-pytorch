common:
  save_interval: 2
  test_interval: 10  # Test every 10 epochs
  val_interval: 5   # Validation every 5 epochs
  log_interval: 100
  max_epoch: 300
  seed: 3401
  amp: False

datasets:
  data_root: '/scratch/eigenscape'
  batch_size: 16  # Increased batch size for better GPU utilization
  tensor_cut: 24000  # 1 second at 24kHz
  num_workers: 4
  fixed_length: 24000  # Use 24,000 samples (1 second) for 2000 batches per epoch
  pin_memory: True

checkpoint:
  resume: False
  checkpoint_path: ''
  disc_checkpoint_path: ''
  save_folder: './checkpoints_mono_nq2/'
  save_location: '${checkpoint.save_folder}/bs${datasets.batch_size}_cut${datasets.tensor_cut}_length${datasets.fixed_length}_' 

optimization:
  lr: 3e-4
  disc_lr: 3e-4

lr_scheduler:
  warmup_epoch: 5

model:
  target_bandwidths: [1.5, 3., 6., 12., 24.]
  sample_rate: 24_000
  channels: 1  # Mono audio
  train_discriminator: True
  audio_normalize: True
  filters: 32
  ratios: [8, 5, 4, 2]
  disc_win_lengths: [2048, 1024, 512, 256, 128]
  disc_hop_lengths: [512, 256, 128, 64, 32]
  disc_n_ffts: [2048, 1024, 512, 256, 128]
  causal: True
  norm: 'weight_norm'
  segment: None
  name: 'my_encodec'
  n_q: 2  # Number of quantizers

distributed:
  data_parallel: False  # Single GPU training
  world_size: 1
  find_unused_parameters: False
  torch_distributed_debug: False
  init_method: tcp

balancer:
  weights:
    l_t: 0.1
    l_f: 1
    l_g: 3
    l_feat: 3

wandb:
  enabled: true
  project: "mono-encodec-nq2"
  name: "mono_encodec_bs8_lr3e-4"
